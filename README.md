# Streamlit LLM Chatbot with RAG (Llama 3)

This is a Streamlit/Ollama LLM Application in a single container.

## How to Run

1. Clone this repository
1. Run `./docker-startup build`
1. Run `./docker-startup deploy`

## References

* [RAG with PDF upload](https://github.com/vndee/local-rag-example)
* [Langchain obtaining embeddings](https://python.langchain.com/v0.1/docs/integrations/text_embedding/ollama/)
* [Ollama blog with embeddings](https://ollama.com/blog/embedding-models)

